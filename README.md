# Loss Comparison for Image Retrieval Challenge

## ğŸ“– Description

This project was developed for a facial image retrieval challenge. The goal is to evaluate the impact of different loss functions (**ArcFace**, **Triplet Loss**, **CLIP Loss**, **Contrastive Loss**) in face retrieval scenarios. All experiments use the **CLIP ViT-B/32** backbone, enhanced with a projection head. The analysis aims to identify the most effective loss for optimizing retrieval performance and robustness to data variation.  
For more details, see the [paper.pdf](paper.pdf).

---

## ğŸ“Š Loss Comparison Table

The following table summarizes the main training settings and results for each loss function:

### Compact comparison of loss functions and training settings

| **Loss**  | **Frz** | **B_s** | **Ep** | **W_d** | **Drp** | **Score** |
|----------|:-------:|:-------:|:------:|:-------:|:-------:|----------:|
| Triplet  | T       | 64      | 45     | 1e-4    | 0.0     | 586.53    |
| CLIP     | T       | 64      | 21     | 1e-4    | 0.3     | 546.53    |
| ArcFace  | F       | 128     | 38     | 1e-4    | 0.3     | **616.98** |


**Legend:**  
- **Frz**: Whether the backbone was frozen (T=True, F=False)  
- **B\_s**: Batch size  
- **Ep**: Number of epochs  
- **W\_d**: Weight decay  
- **Drp**: Dropout  
- **Score**: Final leaderboard score (higher is better)

---

## ğŸ§  Model Overview

- **CLIP + Projection Head:**  
  The backbone is CLIP ViT-B/32, followed by a projection head (MLP) to learn discriminative embeddings.
- **Siamese Setup:**  
  The `siamese_network/` folder contains the Siamese architecture, in which two images are passed through the same backbone and the distance between embeddings is used for the loss (Triplet/Contrastive).
- **Per-Loss Implementations:**  
  - `clip_ArcFace/`: ArcFace loss experiments
  - `clip_ClipLoss/`: CLIP loss experiments
  - `clip_Triplet/`: Triplet loss experiments
- **Key Differences:**  
  - ArcFace and CLIP Loss leverage direct classification/contrast among classes.
  - Triplet and Contrastive Loss focus on distances between embedding pairs/triplets.
  - All models use the CLIP ViT-B/32 backbone.

---

## ğŸ‹ï¸â€â™‚ï¸ Training Details

- **Data Augmentation:**  
  Random crop, horizontal flip, color jitter, resize.
- **Early Stopping:**  
  Validation metric (Top-5) monitoring with a patience of 10 epochs.
- **Evaluation Metrics:**  
  - **Top-1 Accuracy:** Percentage of queries with the correct match at rank 1.
  - **Top-5 / Top-10 Accuracy:** Percentage of queries with the correct match in the top 5/10 results.

---

## âš™ï¸ Installation & Usage

### 1. Clone the repository
```bash
git clone https://github.com/CrispyCocaBoy/Loss_Comparison_for_Image_Retrival_Challenge.git
cd Loss_Comparison_for_Image_Retrival_Challenge
```

### 2. Create a virtual environment and install dependencies
```bash
python -m venv venv
source venv/bin/activate   # or 'venv\Scripts\activate' on Windows
pip install -r requirements.txt
```

### 3. Run training
Each loss has a dedicated folder with its own training script. Example (ArcFace):
```bash
cd clip_ArcFace
python train.py
```
Or for Triplet Loss:
```bash
cd ../clip_Triplet
python train.py
```
Check each folder for specific configuration options.

---

## ğŸ“ Folder Structure

```
Loss_Comparison_for_Image_Retrival_Challenge/
â”œâ”€â”€ clip_ArcFace/        # ArcFace loss implementation & experiments
â”œâ”€â”€ clip_ClipLoss/       # CLIP loss implementation & experiments
â”œâ”€â”€ clip_Triplet/        # Triplet loss implementation & experiments
â”œâ”€â”€ siamese_network/     # Siamese and contrastive loss architectures
â”œâ”€â”€ data/                # Processed datasets
â”œâ”€â”€ data_original/       # Original datasets
â”œâ”€â”€ data_analysis/       # Data analysis scripts/notebooks
â”œâ”€â”€ utilities/           # Utility functions and scripts
â”œâ”€â”€ paper.pdf            # Project paper/report
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ README.md            # Project documentation
```

---

## ğŸš€ Main Commands

- **Training with ArcFace:**  
  `cd clip_ArcFace && python train.py`
- **Training with Triplet Loss:**  
  `cd ../clip_Triplet && python train.py`
- **Training with CLIP Loss:**  
  `cd ../clip_ClipLoss && python train.py`
- **Siamese/Contrastive:**  
  See `siamese_network/` for scripts and usage.
- **Evaluation:**  
  Check each folder for evaluation scripts and usage examples.

---

## ğŸ¤ Contributing

Contributions are welcome!  
To participate:

1. Fork the project
2. Create a feature branch (`git checkout -b feature/new-feature`)
3. Commit your changes
4. Open a pull request describing your changes

---

## ğŸ“„ License

This project is released under the [MIT](LICENSE) license.

---

*Note: The directory listing above may be incomplete. See the [full repository on GitHub](https://github.com/CrispyCocaBoy/Loss_Comparison_for_Image_Retrival_Challenge/tree/master/) for all files and folders.*
